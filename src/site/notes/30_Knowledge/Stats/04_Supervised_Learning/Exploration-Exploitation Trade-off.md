---
{"dg-publish":true,"permalink":"/30-knowledge/stats/04-supervised-learning/exploration-exploitation-trade-off/","tags":["machine-learning","supervised"]}
---


## Definition

> [!abstract] Core Statement
> The **Exploration-Exploitation Trade-off** is the dilemma between ==trying new actions== (exploration) to gather information and ==using known good actions== (exploitation) to maximize reward.

---

> [!tip] Intuition (ELI5): The Restaurant Dilemma
> Do you go to your favorite restaurant (exploit) or try a new one that might be even better (explore)?

---

## The Trade-off

| Strategy | Pros | Cons |
|----------|------|------|
| **Pure Exploitation** | Max short-term reward | Miss better options |
| **Pure Exploration** | Learn everything | Waste time on bad options |
| **Balance** | Optimal long-term | Requires careful tuning |

---

## Solutions

| Algorithm | Approach |
|-----------|----------|
| **ε-greedy** | Explore randomly ε% of time |
| **UCB** | Explore uncertain options |
| **[[30_Knowledge/Stats/04_Supervised_Learning/Thompson Sampling\|Thompson Sampling]]** | Bayesian uncertainty |
| **Annealing** | Decrease exploration over time |

```python
import numpy as np

def epsilon_greedy(Q_values, epsilon=0.1):
    if np.random.random() < epsilon:
        return np.random.randint(len(Q_values))  # Explore
    else:
        return np.argmax(Q_values)  # Exploit
```

---

## Applications

| Domain | Explore | Exploit |
|--------|---------|---------|
| **A/B Testing** | Try new variants | Use best variant |
| **Recommendations** | Show new items | Show popular items |
| **Clinical Trials** | Test new treatments | Use proven treatments |

---

## Related Concepts

- [[30_Knowledge/Stats/04_Supervised_Learning/Thompson Sampling\|Thompson Sampling]] — Bayesian solution
- [[30_Knowledge/Stats/04_Supervised_Learning/Contextual Bandits\|Contextual Bandits]] — With context
- [[30_Knowledge/Stats/06_Experimental_Design/Bayesian AB Testing\|Bayesian AB Testing]] — Related application

---

## When to Use

> [!success] Use Exploration-Exploitation Trade-off When...
> - Refer to standard documentation
> - Refer to standard documentation

---

## When NOT to Use

> [!danger] Do NOT Use When...
> - Dataset is too small for training
> - Interpretability is more important than accuracy

---

## Python Implementation

```python
import numpy as np
import pandas as pd

# Example implementation of Exploration-Exploitation Trade-off
# See documentation for details

data = np.random.randn(100)
print(f"Mean: {np.mean(data):.3f}")
print(f"Std: {np.std(data):.3f}")
```

---

## R Implementation

```r
# Exploration-Exploitation Trade-off in R
set.seed(42)

# Example implementation
data <- rnorm(100)
summary(data)
```

---

## References

- **Book:** Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press. Chapter 2.
